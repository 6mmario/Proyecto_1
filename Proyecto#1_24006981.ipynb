{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83751371-30a9-48a6-8124-e53d853eddc6",
   "metadata": {},
   "source": [
    "# Proyecto 1\n",
    "# Universidad Galileo\n",
    "## Ciencia de Datos en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8305a2d-31a7-40fc-bc05-9b6c9cbdf159",
   "metadata": {},
   "source": [
    "### Mario Obed Morales Güitz\n",
    "### 24006981"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d34f3f-9962-44fc-9ecc-4d2af0f9ff2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Entorno de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065270e2-804a-4a31-8bee-5e046df2c636",
   "metadata": {},
   "source": [
    "## Importando las librerias que se utilizarán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a2b1a-57b1-4535-94c1-908f7584fcdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfa18e-2341-4212-ab1a-2c0d5a4a1e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de Datos\n",
    "sns.set_style(\"darkgrid\")\n",
    "d = np.load('proyecto_training_data.npy') \n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8062139-f4c1-4a6a-ac29-3d6b9bd4a6d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Separando Información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826ec9f-f852-4e3d-a7fa-9f346341bfdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## atasets: entrenamiento(80 %) \n",
    "## validación y pruebas(20 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac561c99-7737-4448-9dcf-4d3d0107e32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Porcentaje = int(df[0].count()*.8)\n",
    "Porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29619ac5-68ca-4295-a407-852b24d10a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Set_Entrenamiento = df.iloc[:Porcentaje]\n",
    "Set_Entrenamiento = Set_Entrenamiento.set_axis(['SalePrice', 'OverallQual', '1stFLrSF','TotRmsAbvGrd', \n",
    "                            'YearBuilt', 'LotFrontage'], \n",
    "                    axis='columns')\n",
    "Set_Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40446b1b-d4de-43da-9797-286160304f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Set_Pruebas = df.iloc[Porcentaje:]\n",
    "Set_Pruebas = Set_Pruebas.set_axis(['SalePrice', 'OverallQual', '1stFLrSF','TotRmsAbvGrd', 'YearBuilt', 'LotFrontage'], \n",
    "                                   axis='columns')\n",
    "Set_Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c46d3a-a825-4074-935b-76309568ecbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5263c4-b1ba-40b3-9e13-1214a7c7e4db",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. media\n",
    "2. valor m´aximo\n",
    "3. valor m´ınimo\n",
    "4. rango(peak to peak, no el rango del tensor que por ser vector sabemos que es 1)\n",
    "5. desviaci´on est´andar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce4739-5d2b-467a-a25c-becb31dc1f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Media = Set_Entrenamiento.mean(axis=0)\n",
    "Valor_Maximo =  Set_Entrenamiento.max(axis=0)\n",
    "Valor_Minimo = Set_Entrenamiento.min(axis=0)\n",
    "Desviacion_Estandar = Set_Entrenamiento.std(axis=0)\n",
    "Rango = Valor_Maximo - Valor_Minimo\n",
    "\n",
    "Resultados = ({'Media':pd.Series(Media,dtype=float), 'Valor_Maximo':pd.Series(Valor_Maximo,dtype=float), 'Valor_Minimo':pd.Series(Valor_Minimo,dtype=float),\n",
    "             'Desviacion_Estandar':pd.Series(Desviacion_Estandar,dtype=float), 'Rango':pd.Series(Rango)})\n",
    "dfAnalisis = pd.DataFrame(Resultados)\n",
    "dfAnalisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f4c17-b402-4a60-a79e-965b42d98d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Set_Entrenamiento.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d25cb-54cd-433a-8572-b52a319a1479",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Usando Seaborn para graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4b8f8-2c40-488d-bb43-43423b088584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quitamos las advertencias, pues es solo ajustes de tamaño\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "for i in Set_Entrenamiento.columns.values:\n",
    "    ax = sns.displot(Set_Entrenamiento[i], edgecolor='k', color=\"#FFE4B5\")\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Conteo')\n",
    "    plt.gcf().set_size_inches(10, 6)  #  tamanio de la figura (ancho, alto)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067bbf39-bfec-4131-a0e3-9651469fd638",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Para cada variable independiente x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ce068f-7b65-42e1-8069-aedad1b16d06",
   "metadata": {},
   "source": [
    "- Calcular el coeficiente de correlación entre x y y.\n",
    "- Graficar x vs y(scatterplot) usando matplotlib.\n",
    "- Colocar el coeficiente de correlación y colocarlo como parte del título de la gráfica.\n",
    "- Basado en la gráfica y el coeficiente de correlación de cada par x,y elegir las 2 variables \n",
    "con más potencial predictivo es decir las 2 variables que presentan mayor correlación\n",
    "entre dicha variable y la variable dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625372f8-9cbb-45d6-876c-0f85847df22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Correlaciones = []\n",
    "variables = []\n",
    "for i in Set_Entrenamiento.columns.values:\n",
    "    Correlacion = (pd.DataFrame(Set_Entrenamiento[[i,'SalePrice']]).corr().iloc[0,1])\n",
    "    Correlaciones.append(Correlacion)\n",
    "    variables.append(i)\n",
    "    plt.scatter(Set_Entrenamiento[i], Set_Entrenamiento['SalePrice'], edgecolor='k', color=\"#DAA520\")\n",
    "    plt.title(str(i)+' vs ' + str('SalePrice') + ' / Corr:  '+str((Correlacion)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380cfa2-e5b7-421f-b143-ca4688178e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_corr_variables = pd.DataFrame({'variables':variables, \n",
    "                                   'Correlaciones':Correlaciones})\n",
    "top_corr_variables.sort_values(by='Correlaciones', ascending = False)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce3eb2-0640-4278-a38b-b5c9e6827c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(Set_Entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352cd2d-5484-4887-b3a1-c1b5ab2914cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Mejor_Potencial = pd.DataFrame({'Correlaciones':Correlaciones},index=[Set_Entrenamiento.columns.values])\n",
    "Mejor_Potencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26bf333-99fc-4327-85f8-c2da0d0b4c64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Crear una función para entrenar un modelo de Regresion Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081908da-2885-496c-b50d-0b6b6fa4c223",
   "metadata": {},
   "source": [
    "    6.1 Vector con la variable independiente x,\n",
    "    6.2 Vector con la variable dependiente y,\n",
    "    6.3 un entero epochs que indica por cuantas iteraciones entrenar el modelo.\n",
    "    6.4 un entero imprimir error cada , que nos indica cada cuantas iteraciones queremos imprimir a través de print: el nu´mero de iteración, el error del modelo en esa iteración, si imprimir error cada = 10, se despliega en pantalla el error en las iteraciones: 10,20,30,40,50.\n",
    "    6.5 escalar α(learning rate): es usado como parte de la expresión matemática para actualizar en cada iteración los parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c44cf8-83ba-4758-b3cd-991562fab1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _regresion():\n",
    "    #Constructor\n",
    "    def __init__(self, x, y, epochs, imprimir_error_cada, learning_rate):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.b0 = 0\n",
    "        self.b1 = 0\n",
    "        self.epochs = epochs\n",
    "        self.Error = []\n",
    "        self.Modelo = {}  \n",
    "        self.VectorY = np.reshape(self.y, (-1,1))\n",
    "        self.VectorUnos = np.ones_like(self.x).reshape(-1,1)\n",
    "        self.VectorXUnos = np.hstack([np.reshape(self.x,(-1,1)),self.VectorUnos])\n",
    "        self.betas = np.reshape([[self.b1],[self.b0]],(-1,1))\n",
    "      \n",
    "        for i in range(epochs):\n",
    "            self.y_hat = np.dot(self.VectorXUnos, self.betas)\n",
    "            self.Errores = 1/(2*self.VectorY.shape[0]) * sum((self.VectorY - self.y_hat)**2)\n",
    "            self.Error.append(self.Errores[0])\n",
    "            if i%round(imprimir_error_cada) == 0:\n",
    "                print('\\nIteraciones: ', i, '    Error: ',self.Errores[0])\n",
    "            self.gradiante = np.reshape(learning_rate*(1/self.VectorY.shape[0]*sum((self.y_hat - self.VectorY)*self.VectorXUnos)),(-1,1))\n",
    "            self.betas = self.betas - self.gradiante\n",
    "            self.Modelo[i] = [self.betas, self.y_hat, self.VectorY, self.x]\n",
    "    \n",
    "    #Modelo\n",
    "    def modelo(self):\n",
    "        return self.Modelo , np.array(self.Error)\n",
    "    \n",
    "    #Errores del Modelo\n",
    "    @staticmethod\n",
    "    def error(error):\n",
    "        fig_1 = plt.figure(figsize = (9,7))\n",
    "        ax = fig_1.add_axes([0.02, 0.02, 0.6, 0.6])\n",
    "        ax.plot(error, color=\"#ADD8E6\")\n",
    "        ax.set_title(\"Errores del modelo\")\n",
    "        ax.set_xlabel(\"Numero de Iteraciones\")\n",
    "        ax.set_ylabel('Error')\n",
    "        plt.show()\n",
    "    \n",
    "    #Evolución del Modelo\n",
    "    @staticmethod\n",
    "    def evolucion(Modelo, n):\n",
    "        for i in list(Modelo.keys()):\n",
    "            if i%round(n) == 0:\n",
    "                fig_2 = plt.figure(figsize = (9,7))\n",
    "                ax_2 = fig_2.add_axes([0.02, 0.02, 0.6, 0.6])\n",
    "                y_hat = Modelo[i][1]\n",
    "                y = Modelo[i][2]\n",
    "                x = Modelo[i][3]\n",
    "                ax_2.scatter(x , y, edgecolor='k', color=\"#8A2BE2\")\n",
    "                ax_2.plot(x, y_hat , linestyle ='solid', color ='r', label = 'Iteración:  %d' % i)\n",
    "                ax_2.set_title(\"Iteración: \"+str(i))\n",
    "                ax_2.legend()\n",
    "                ax_2.set_xlabel(\"X\")\n",
    "                ax_2.set_ylabel(\"Y\")\n",
    "                plt.show()\n",
    "    \n",
    "    #Método de Predicción \n",
    "    def prediccion(self, M):\n",
    "        self.M = M\n",
    "        self.VectorUnos = np.ones_like(self.M).reshape(-1,1)\n",
    "        self.VectorXUnos = np.hstack([np.reshape(self.M,(-1,1)),self.VectorUnos])\n",
    "        for i in range(self.epochs):\n",
    "            self.Y_pred = np.dot(self.VectorXUnos, self.betas)\n",
    "        return self.Y_pred\n",
    "    \n",
    "    #Compara Predicciones\n",
    "    @staticmethod\n",
    "    def compara_prediccion(Mpropio, Msklearn, Predecir, Modelo):\n",
    "        MpropioResultado = Mpropio.prediccion(Predecir.reshape(-1,1))\n",
    "        MsklearnResultado = Msklearn.predict(Predecir.reshape(-1,1)) \n",
    "        Promedio = (MpropioResultado + MsklearnResultado)/2\n",
    "        fig_3 = plt.figure(figsize = (9,7))\n",
    "        ax_3 = fig_3.add_axes([0.02, 0.02, 0.6, 0.6])\n",
    "        for i in list(Modelo.columns.values):\n",
    "            y = Modelo[i]\n",
    "            ax_3.scatter(Predecir , y, edgecolor='k', color=\"#FAEBD7\")\n",
    "            ax_3.plot(Predecir, MpropioResultado, color=\"#FFEBCD\", label = '_regresion: ')\n",
    "            ax_3.plot(Predecir, MsklearnResultado, color=\"#FFFACD\", label = 'Msklearn: ')\n",
    "            ax_3.plot(Predecir, Promedio, color=\"orange\", label = 'Promedio: ')\n",
    "            ax_3.set_title(\"Comparativa\")\n",
    "            ax_3.legend()\n",
    "            ax_3.set_xlabel(\"X\")\n",
    "            ax_3.set_ylabel('Y')\n",
    "            plt.show()\n",
    "        return MpropioResultado, MsklearnResultado, Promedio\n",
    "    \n",
    "    #Compara Errores\n",
    "    @staticmethod\n",
    "    def compara_errores(modelos, modelos2, prueba1, prueba2, set_prueba):\n",
    "        labels = ['OverallQual', '1stFLrSF']\n",
    "        Error_regresion = metrics.mean_squared_error(modelos[0], prueba1)\n",
    "        Error_Msklearn = metrics.mean_squared_error(modelos[1], prueba1)\n",
    "        Error_Promedio = metrics.mean_squared_error(modelos[2], prueba1)\n",
    "        \n",
    "        Error2_regresion = metrics.mean_squared_error(modelos2[0], prueba2)\n",
    "        Error2_Msklearn = metrics.mean_squared_error(modelos2[1], prueba2)\n",
    "        Error2_Promedio = metrics.mean_squared_error(modelos2[2], prueba2)\n",
    "        \n",
    "        Errores_regresion = [Error_regresion,Error2_regresion]\n",
    "        Errores_Msklearn = [Error_Msklearn,Error2_Msklearn]\n",
    "        Errores_Promedio = [Error_Promedio,Error2_Promedio]\n",
    "        \n",
    "        T = np.arange(len(labels))\n",
    "        fig_4 = plt.figure(figsize = (9,7))\n",
    "        ax = fig_4.add_axes([0.01, 0.01, 0.6, 0.6])\n",
    "        ax.set_xticks(T + 0.90/3)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.bar(T, Errores_regresion, width=0.30,  edgecolor='k', color=\"#708090\", label=\"_regresion\")\n",
    "        ax.bar(T+ 0.30, Errores_Msklearn, width=0.30,  edgecolor='k', color=\"#E6E6FA\", label=\"Msklearn\")\n",
    "        ax.bar(T+ 0.60, Errores_Promedio, width=0.30, edgecolor='k', color=\"#F0FFF0\", label=\"Promedio\")\n",
    "        ax.legend()\n",
    "        ax.set_title(\"Comparativa\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53a9ab-15d7-41bd-94e3-6566161c9f81",
   "metadata": {},
   "source": [
    "## Entrenando modelos de regresión - con OverallQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b84d8-4b71-4774-83a4-92d51c8d7397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NPSales = np.reshape(np.array(Set_Entrenamiento['SalePrice']), (-1, 1))\n",
    "NPOverallQual = np.reshape(np.array(Set_Entrenamiento['OverallQual']), (-1, 1))\n",
    "NPFirst_Floor_square_feet = np.reshape(np.array(Set_Entrenamiento['1stFLrSF']), (-1, 1))\n",
    "Epoch = 5001\n",
    "Imprimir = 1000\n",
    "Escalar = 0.01\n",
    "RegresionModelo1 = _regresion(NPOverallQual, NPSales, Epoch, Imprimir, Escalar)\n",
    "Rmodelos, Rerrores = RegresionModelo1.modelo()\n",
    "_regresion.error(Rerrores)\n",
    "_regresion.evolucion(Rmodelos,Imprimir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129af8d5-1e30-4ebd-a1ad-c7619ea09eb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entrenando modelos de regresión - con 1stFlrSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496d50d-e8f9-4f36-9d2e-2c22f146c194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Epoch = 51\n",
    "Imprimir = 10\n",
    "Escalar = 0.0000001\n",
    "RegresionModelo2 = _regresion(NPFirst_Floor_square_feet, NPSales, Epoch, Imprimir, Escalar)\n",
    "Rmodelos2, Rerrores2 = RegresionModelo2.modelo()\n",
    "_regresion.error(Rerrores2)\n",
    "_regresion.evolucion(Rmodelos2,Imprimir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b3aed-6594-4836-9023-85ef64af9308",
   "metadata": {},
   "source": [
    "## Predicciones modelo propio vs SK-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b960e2b-9676-4c37-951d-ead670fa7677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Sci_NPOverallQual = LinearRegression()\n",
    "Sci_NPOverallQual.fit(NPOverallQual, NPSales)\n",
    "Sci_NPFirst_Floor_square_feet = LinearRegression()\n",
    "Sci_NPFirst_Floor_square_feet.fit(NPFirst_Floor_square_feet, NPSales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e344806-3823-4f3d-8159-b9048f2e37ec",
   "metadata": {},
   "source": [
    "## Predicciones con modelo propio, Scikit Learn y Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f3da3-05f5-41f3-84c8-f7daccdc4f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Pruebas_OverallQual = np.reshape(np.array(Set_Pruebas['OverallQual']), (-1, 1))\n",
    "Pruebas_Floor_square_feet = np.reshape(np.array(Set_Pruebas['1stFLrSF']), (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef54bb-487a-425c-9c94-1cf8666173cb",
   "metadata": {},
   "source": [
    "## Comparando modelos\n",
    "    Modelo 1 - Modelo Propio\n",
    "    Modelo 2 - Modelo Scikit Learn\n",
    "    Modelo 3 - Modelo Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04008afa-ee3c-4057-9ce7-822f6b5593c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelos_OverallQual = _regresion.compara_prediccion(RegresionModelo1, Sci_NPOverallQual, Pruebas_OverallQual, Set_Pruebas)\n",
    "modelos_1stFlrSF = _regresion.compara_prediccion(RegresionModelo2, Sci_NPFirst_Floor_square_feet, Pruebas_Floor_square_feet, Set_Pruebas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bddf8cd-b18c-466c-8103-c7da6c48b8b2",
   "metadata": {},
   "source": [
    "## Comparativa de errores de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c03528-7e79-48e4-b993-40750080d066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_regresion.compara_errores(modelos_OverallQual, modelos_1stFlrSF, Pruebas_OverallQual, Pruebas_Floor_square_feet, Set_Pruebas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c43c-91f8-4be5-8e08-e7b9dc603e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167596f-b4af-48c4-8afe-68c144a0aeb7",
   "metadata": {},
   "source": [
    "- OverallQual: todos los modelos presentan un error muy similar, aproximadamente el 20% de los datos. Sin embargo, la regresión específicamente desarrollada para esta tarea resulta ser el modelo con el menor error. \n",
    "- 1stFlrSF: el modelo de regresión de scikit-learn sobresale como el mejor, mostrando un error significativamente menor en comparación con el modelo generado para esta tarea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
